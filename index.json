[
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/",
	"title": "Building a Real-time Q&amp;A and Poll System with AWS AppSync, Lambda, DynamoDB",
	"tags": [],
	"description": "",
	"content": "Building a Real-time Q\u0026amp;A and Poll System with AWS AppSync, Lambda, DynamoDB Overview This workshop guides you step-by-step to build a real-time Q\u0026amp;A and Poll platform for online events using modern AWS serverless services. You will practice deploying a NoSQL database with DynamoDB, authenticating users with Cognito, building a real-time GraphQL API with AppSync, implementing business logic with Lambda, and monitoring the system via CloudWatch.\nContents Introduction\nOverview of the real-time interaction problem for events and the serverless solution architecture on AWS.\nDeploying the Database with DynamoDB\nCreate a DynamoDB table using Single-Table Design Store event, question, and poll data User Authentication with Cognito\nCreate a User Pool Configure authentication and access control Building the GraphQL API with AppSync\nCreate an AppSync API Define the schema, set up authentication Connect with Lambda and DynamoDB Implementing Business Logic with Lambda\nCreate and deploy Lambda functions for Q\u0026amp;A and Poll Connect Lambda with AppSync System Monitoring and Testing\nMonitor activities via CloudWatch Practice submitting questions, voting, and viewing real-time results Follow each step to complete a real-time Q\u0026amp;A and Poll system, a practical solution\n"
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/3-accessibilitytoinstances/3.1-amazon-dynamodb/",
	"title": "Deploying the Database with Amazon DynamoDB",
	"tags": [],
	"description": "",
	"content": "In this lab, we will create a single DynamoDB table to store all data for the application.\nAccess the DynamoDB Console\nLog in to the AWS Management Console. In the search bar, type DynamoDB and select the DynamoDB service. Create a New Table:\nOn the DynamoDB main page, click the Create table button.\nConfigure Table Details:\nYou will be taken to the configuration page. Please enter the following information accurately: Table name: Enter RealtimeQAPlatform-Table. This name will be used in our Lambda code later. Partition key (PK): Name: PK Data type: String Explanation: This is the primary key used by DynamoDB to distribute data across physical partitions. It will store values like EVENT#\u0026lt;eventId\u0026gt;. Sort key (SK): Check the Add sort key box. Name: SK Data type: String Explanation: This key allows us to store multiple types of data with the same Partition Key and sort them. We will use it to categorize data, e.g., METADATA, QUESTION#\u0026lt;questionId\u0026gt;, POLL#\u0026lt;pollId\u0026gt;. Table settings: Keep the Default settings. The On-demand mode is selected by default, which is optimal for this workshop, allowing you to pay only for the resources you actually use without complex configuration. Click the Create table button at the bottom right to finish. The table creation process will take a few seconds.\n"
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "As online events (webinars, workshops, livestreams) become increasingly popular, maintaining engagement and collecting feedback from participants is a major challenge. Traditional chat tools often lead to information overload, high latency, and lack of filtering capabilities, reducing interaction effectiveness and user experience.\nThis lab is designed to help you approach and directly practice building a complete solution to address these challenges using AWS serverless services. Specifically, you will be guided to:\nAWS AppSync: Build a flexible GraphQL API, manage real-time connections (WebSocket) through GraphQL Subscriptions for instant data updates. AWS Lambda: Deploy business logic to handle requests such as creating questions, upvoting, and managing polls without server management. Amazon DynamoDB: Design and implement a high-performance NoSQL database using Single-Table Design to store and retrieve data with millisecond latency. Amazon Cognito: Integrate a secure user authentication and management system, enabling role-based access for features like event and poll creation. Amazon CloudWatch: Use Amazon CloudWatch to monitor and manage application activities, including events, errors, and application health. Architecture Model AWS AppSync: Acts as the GraphQL API gateway and is the single endpoint for frontend communication. AppSync handles queries (read data), mutations (modify data), and manages subscriptions to push real-time data to clients. AWS Lambda: Serves as the logic layer. When AppSync receives a request that requires complex business logic (e.g., upvoteQuestion), it invokes the corresponding Lambda function. Lambda executes the code and interacts with other services like DynamoDB. Amazon DynamoDB: The chosen NoSQL database to store all application data (events, questions, polls, users). Single-Table Design is applied to optimize query efficiency and reduce latency. Amazon Cognito: Provides a complete user identity management solution, from registration, login, and password recovery to session management. It integrates directly with AppSync to secure API endpoints. Amazon CloudWatch: Used to monitor and manage application activities, including events, errors, and application "
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/4-s3log/4.1-appsync/",
	"title": "Setting Up a GraphQL API with AWS AppSync",
	"tags": [],
	"description": "",
	"content": " Create a New API In the AWS Management Console search bar, type AppSync and select the service.\nOn the AppSync main page, click Create API. Select Build from scratch and click Next. API name: Enter RealtimeQAPlatform-API and click Next. Select Create GraphQL resource later, then click Next. Review and click Create API. Configure Authentication Methods This is an important step to secure your API. We will configure two layers of protection: API Key: For public access, not requiring users to log in (e.g., viewing questions). Amazon Cognito: For actions that require identification (e.g., creating events, upvoting). Configure these in the left menu of the API you just created:\nSelect Settings. Primary authorization mode: Select Add API key. You can keep the default expiration time or customize it using Edit. Additional authorization modes: Click Add. Authorization mode: Select Amazon Cognito User Pools. Cognito User Pool: Select Region: AP-Southeast-1 Select the User Pool you created (RealtimeQAPlatform-UserPool). Click Add. Define the GraphQL Schema The schema is the \u0026ldquo;contract\u0026rdquo; that defines all data types and actions (query, mutation, subscription) your API supports.\nIn the left menu, select Schema.\nDelete all sample content in the editor.\nPaste the complete schema below. This schema defines the Event, Question, Poll, User types and all necessary actions.\ntype Event { id: ID! name: String! description: String creatorId: ID questions: [Question] polls: [Poll] createdAt: AWSDateTime! } type Question { id: ID! eventId: ID! content: String! author: User! upvotes: Int! createdAt: AWSDateTime! } type Poll { id: ID! eventId: ID! questionText: String! options: [PollOption!]! totalVotes: Int! } type PollOption { text: String! votes: Int! } type User { id: ID! name: String! } input CreateEventInput { name: String! description: String creatorId: ID! } input CreateQuestionInput { eventId: ID! content: String! authorId: ID! authorName: String! } input UpvoteQuestionInput { eventId: ID! questionId: ID! userId: ID! } input PollOptionInput { text: String! } input CreatePollInput { eventId: ID! questionText: String! options: [PollOptionInput!]! } input SubmitPollVoteInput { eventId: ID! pollId: ID! optionText: String! userId: ID! } type Query { getEvent(id: ID!): Event @aws_api_key listEvents: [Event] @aws_api_key } type Mutation { createEvent(input: CreateEventInput!): Event @aws_cognito_user_pools createQuestion(input: CreateQuestionInput!): Question @aws_api_key upvoteQuestion(input: UpvoteQuestionInput!): Question @aws_api_key createPoll(input: CreatePollInput!): Poll @aws_cognito_user_pools submitPollVote(input: SubmitPollVoteInput!): Poll @aws_api_key } type Subscription { onQuestionUpdated(eventId: ID!): Question @aws_subscribe(mutations: [\u0026#34;createQuestion\u0026#34;, \u0026#34;upvoteQuestion\u0026#34;]) onPollUpdated(eventId: ID!): Poll @aws_subscribe(mutations: [\u0026#34;createPoll\u0026#34;, \u0026#34;submitPollVote\u0026#34;]) } Click Save Schema. "
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/4-s3log/4.2-creates3bucket/",
	"title": "Deploy Logic Functions with AWS Lambda",
	"tags": [],
	"description": "",
	"content": "1. Create Lambda Functions\nIn the AWS Management Console search bar, type Lambda and select the service.\nYou will need to create each required function. The process for each function is similar: Create function -\u0026gt; Configure -\u0026gt; Paste code -\u0026gt; Deploy.\nThen select Function in the left menu to view the list of Lambda Functions\nGeneral process for each function:\nClick Create function. Select Author from scratch. Function name: Enter the function name (e.g., createEventFunction). Runtime: Select Node.js 18.x. Permissions: Expand Change default execution role, select Use an existing role, and choose RealtimeQAPlatform-LambdaRole created in Lab 3. Click Create function. After the function is created:\nGo to the Code tab and paste the corresponding code into the index.mjs file. Go to the Configuration tab -\u0026gt; Environment variables -\u0026gt; Edit, add a new environment variable:\nKey: TABLE_NAME Value: RealtimeQAPlatform-Table Return to the Code tab and click Deploy. A. createEventFunction\nPurpose: Handles the creation of a new event.\nCode (index.mjs):\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, PutCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; import { randomUUID } from \u0026#34;crypto\u0026#34;; const client = new DynamoDBClient({}); const docClient = DynamoDBDocumentClient.from(client); const TABLE_NAME = process.env.TABLE_NAME; export const handler = async (event) =\u0026gt; { const { name, description, creatorId } = event.input; const eventId = randomUUID(); const createdAt = new Date().toISOString(); const newEvent = { id: eventId, name, description, creatorId, createdAt, PK: `EVENT#${eventId}`, SK: `METADATA`, }; await docClient.send(new PutCommand({ TableName: TABLE_NAME, Item: newEvent, })); return newEvent; }; B. listEventsFunction\nPurpose: Retrieves the list of all created events.\nCode (index.mjs):\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, ScanCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; const client = new DynamoDBClient({}); const docClient = DynamoDBDocumentClient.from(client); const TABLE_NAME = process.env.TABLE_NAME; export const handler = async () =\u0026gt; { const command = new ScanCommand({ TableName: TABLE_NAME, FilterExpression: \u0026#34;SK = :metadata\u0026#34;, ExpressionAttributeValues: { \u0026#34;:metadata\u0026#34;: \u0026#34;METADATA\u0026#34; }, }); const { Items } = await docClient.send(command); return Items || []; }; C. createQuestionFunction\nPurpose: Handles the creation of a new question in an event.\nCode (index.mjs):\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, PutCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; import { randomUUID } from \u0026#34;crypto\u0026#34;; const client = new DynamoDBClient({}); const docClient = DynamoDBDocumentClient.from(client); const TABLE_NAME = process.env.TABLE_NAME; export const handler = async (event) =\u0026gt; { const { eventId, content, authorId, authorName } = event.input; const questionId = randomUUID(); const createdAt = new Date().toISOString(); const newQuestion = { id: questionId, eventId, content, author: { id: authorId, name: authorName }, upvotes: 0, createdAt, PK: `EVENT#${eventId}`, SK: `QUESTION#${questionId}`, }; await docClient.send(new PutCommand({ TableName: TABLE_NAME, Item: newQuestion, })); return newQuestion; }; D. upvoteQuestionFunction\nPurpose: Handles the logic to \u0026ldquo;toggle\u0026rdquo; upvote/un-upvote for a question.\nCode (index.mjs):\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, PutCommand, GetCommand, UpdateCommand, DeleteCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; const client = new DynamoDBClient({}); const docClient = DynamoDBDocumentClient.from(client); const TABLE_NAME = process.env.TABLE_NAME; export const handler = async (event) =\u0026gt; { const { eventId, questionId, userId } = event.input; const pk = `EVENT#${eventId}`; const questionSk = `QUESTION#${questionId}`; const voteSk = `VOTE#Q#${questionId}#U#${userId}`; const { Item: existingVote } = await docClient.send(new GetCommand({ TableName: TABLE_NAME, Key: { PK: pk, SK: voteSk } })); if (existingVote) { await docClient.send(new DeleteCommand({ TableName: TABLE_NAME, Key: { PK: pk, SK: voteSk } })); await docClient.send(new UpdateCommand({ TableName: TABLE_NAME, Key: { PK: pk, SK: questionSk }, UpdateExpression: \u0026#34;SET upvotes = upvotes - :dec\u0026#34;, ExpressionAttributeValues: { \u0026#34;:dec\u0026#34;: 1 }, })); } else { await docClient.send(new PutCommand({ TableName: TABLE_NAME, Item: { PK: pk, SK: voteSk, questionId, userId } })); await docClient.send(new UpdateCommand({ TableName: TABLE_NAME, Key: { PK: pk, SK: questionSk }, UpdateExpression: \u0026#34;SET upvotes = upvotes + :inc\u0026#34;, ExpressionAttributeValues: { \u0026#34;:inc\u0026#34;: 1 }, })); } const { Item: updatedQuestionData } = await docClient.send(new GetCommand({ TableName: TABLE_NAME, Key: { PK: pk, SK: questionSk } })); return updatedQuestionData; }; E. createPollFunction\nPurpose: Handles the creation of a new poll.\nCode (index.mjs):\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, PutCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; import { randomUUID } from \u0026#34;crypto\u0026#34;; const client = new DynamoDBClient({}); const docClient = DynamoDBDocumentClient.from(client); const TABLE_NAME = process.env.TABLE_NAME; export const handler = async (event) =\u0026gt; { const { eventId, questionText, options } = event.input; const pollId = randomUUID(); const optionsWithVotes = options.map(option =\u0026gt; ({ text: option.text, votes: 0 })); const newPoll = { id: pollId, eventId, questionText, totalVotes: 0, options: optionsWithVotes, PK: `EVENT#${eventId}`, SK: `POLL#${pollId}`, }; await docClient.send(new PutCommand({ TableName: TABLE_NAME, Item: newPoll, })); return newPoll; }; F. submitPollVoteFunction\nPurpose: Handles user voting for a poll.\nCode (index.mjs):\nimport { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; import { DynamoDBDocumentClient, PutCommand, UpdateCommand, GetCommand } from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; const client = new DynamoDBClient({}); const docClient = DynamoDBDocumentClient.from(client); const TABLE_NAME = process.env.TABLE_NAME; export const handler = async (event) =\u0026gt; { const { eventId, pollId, optionText, userId } = event.input; const pk = `EVENT#${eventId}`; const pollSk = `POLL#${pollId}`; const voteSk = `VOTE#P#${pollId}#U#${userId}`; const { Item: currentPoll } = await docClient.send(new GetCommand({ TableName: TABLE_NAME, Key: { PK: pk, SK: pollSk }})); if (!currentPoll) throw new Error(\u0026#34;Poll not found.\u0026#34;); const optionIndex = currentPoll.options.findIndex(opt =\u0026gt; opt.text === optionText); if (optionIndex === -1) throw new Error(\u0026#34;Option not found.\u0026#34;); const updatePollCmd = new UpdateCommand({ TableName: TABLE_NAME, Key: { PK: pk, SK: pollSk }, UpdateExpression: `SET options[${optionIndex}].votes = options[${optionIndex}].votes + :inc, totalVotes = totalVotes + :inc`, ExpressionAttributeValues: { \u0026#34;:inc\u0026#34;: 1 }, ReturnValues: \u0026#34;ALL_NEW\u0026#34; }); try { await docClient.send(new PutCommand({ TableName: TABLE_NAME, Item: { PK: pk, SK: voteSk, userId, votedOption: optionText }, ConditionExpression: \u0026#34;attribute_not_exists(SK)\u0026#34; })); const { Attributes } = await docClient.send(updatePollCmd); return Attributes; } catch (error) { if (error.name === \u0026#39;ConditionalCheckFailedException\u0026#39;) { throw new Error(\u0026#34;User has already voted on this poll.\u0026#34;); } throw error; } }; "
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/2-prerequiste/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Before starting the lab, please ensure you have all the necessary requirements and tools to ensure a smooth hands-on experience.\n2.1. AWS Account Requirements An active AWS account has been created. The account has access to the following services: Amazon DynamoDB AWS Lambda Amazon Cognito AWS AppSync AWS IAM (Identity and Access Management) Successfully logged in to the AWS Management Console. 2.2. Basic Knowledge Basic understanding of the AWS Management Console interface and navigation. Basic knowledge of JavaScript (Node.js) to understand and customize Lambda function code. Basic understanding of API concepts, especially GraphQL, is an advantage. Basic knowledge of React and command line usage. 2.3. Required Tools A modern web browser such as Google Chrome, Mozilla Firefox, or Microsoft Edge. (Optional) A code editor like Visual Studio Code to review and prepare code snippets before pasting them into the Lambda Console. Node.js (version 18.x or higher) and npm installed on "
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/3-accessibilitytoinstances/3.2-private-instance/",
	"title": "User Authentication with Amazon Cognito",
	"tags": [],
	"description": "",
	"content": " Access the Amazon Cognito Console\nIn the AWS Management Console search bar, type Cognito and select the service. Create a New User Pool\nOn the Cognito main page, click the Create user pool button. Configure the User Pool\nFor Application type, select Single-page application (SPA)\nEnter the name RealtimeQAPlatform-UserPool\nIn config, select email Next, click Create user directory Configure Callback URL\nThis is a crucial step so Cognito knows where to redirect users after successful login.\nAfter the User Pool is created, go to the user pool tab -\u0026gt; Click on the RealtimeQAPlatform-UserPool to enter the management interface: Scroll down and click on App client in the left menu.\nSelect Create app client Enter the name RealtimeQAPlatform-userpool\nClick Create app client After successful creation, you will see the following interface:\nSelect the Login pages section\nIn the Managed login pages configuration section, click edit In Allowed callback URLs, enter http://localhost:3000/event\nIn Allowed sign-out URLs, enter http://localhost:3000/auth\nExplanation: These are the URLs Cognito will use to redirect users after login or logout. We will use them in our React application to ensure users are redirected correctly. Scroll to the bottom and click Save changes.\n"
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/3-accessibilitytoinstances/",
	"title": "Building the Backend Platform on AWS",
	"tags": [],
	"description": "",
	"content": "In this section, we will build the entire backend infrastructure for the application on AWS. All operations will be performed directly on the AWS Management Console to provide the most intuitive view of how the services connect with each other.\nIntroduction to Amazon DynamoDB and Single-Table Design Amazon DynamoDB is a fully managed NoSQL database service that delivers fast and predictable performance with seamless scalability. Unlike traditional relational databases (SQL), DynamoDB stores data as key-value pairs, optimized for high-speed queries.\nTo maximize the power of DynamoDB, we will apply a robust design approach called Single-Table Design. Instead of creating multiple tables for each data type (Events, Questions, Polls), we will store them all in a single table.\nBenefits of Single-Table Design:\nHigh performance: Significantly reduces the number of database queries. Instead of \u0026ldquo;JOIN\u0026quot;ing multiple tables, we can retrieve all data related to an event with a single Query command. Cost optimization: Reduces operational costs by focusing resources on a single table instead of provisioning resources for multiple separate tables. Scalability: Easy to scale and manage as the application grows. Introduction to Amazon Cognito Amazon Cognito is a service that provides secure and scalable user identity management. It allows us to easily add registration, login, and access control features to web and mobile applications.\nIn our application, Cognito will act as the \u0026ldquo;gatekeeper,\u0026rdquo; ensuring that only valid users can perform important actions such as creating events or polls.\nContents 3.1. Deploying the Database with Amazon DynamoDB\n3.2. User Authentication with Amazon Cognito\n"
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/3-accessibilitytoinstances/3.3-iam/",
	"title": "Configuring Permissions with AWS IAM",
	"tags": [],
	"description": "",
	"content": "In this section, we will configure an IAM Role for the Lambda functions.\nStart the Role Creation Process In the AWS Management Console search bar, type IAM and select the service. In the left menu, select Roles. Click the Create role button. Select Trusted Entity Type Trusted entity type: Select AWS service. Use case: Select Lambda. This means we are creating a Role specifically for AWS Lambda to use. Click Next. Attach Permission Policies Attach the policy that allows Lambda to write logs:\nIn the permissions search box, type AWSLambdaBasicExecutionRole. Check the box next to this policy. This policy grants Lambda the minimum permissions needed to write logs to Amazon CloudWatch, which is crucial for debugging. Click Next. Name and Complete Role Creation Role name: Choose a recognizable name, e.g., RealtimeQAPlatform-LambdaRole. Review the information and click Create role. Add Custom Permission for DynamoDB Access Now we need to grant this Role additional permissions so it can read and write to the DynamoDB table we created.\nIn the list of Roles, find and click on the RealtimeQAPlatform-LambdaRole you just created. In the Permissions tab, click Add permissions and select Create inline policy. You will be taken to the policy editor. Select the JSON tab.\nDelete the default content and paste the following JSON. This defines a specific set of permissions for our DynamoDB table.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowDynamoDBActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34;, \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:dynamodb:YOUR_REGION:YOUR_ACCOUNT_ID:table/RealtimeQAPlatform-Table\u0026#34;, \u0026#34;arn:aws:dynamodb:YOUR_REGION:YOUR_ACCOUNT_ID:table/RealtimeQAPlatform-Table/index/*\u0026#34; ] } ] } Click Next. Note: Replace YOUR_ACCOUNT_ID and YOUR_REGION with your AWS account information.\nPolicy name: Give the policy a name, e.g., DynamoDBAccessPolicy. Click Create "
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/4-s3log/4.3-connectapi/",
	"title": "Connecting API and Logic",
	"tags": [],
	"description": "",
	"content": "Connecting API and Logic Introduction to Data Sources and Resolvers Currently, we have an AppSync API (the entry point) and a set of Lambda functions (the processing brains), but they don\u0026rsquo;t know about each other yet. To connect them, we need to use two core concepts in AppSync:\nData Sources:\nThis is a configuration in AppSync so it \u0026ldquo;knows\u0026rdquo; about another AWS resource, such as a Lambda function or a DynamoDB table. We will create a Data Source for each Lambda function we have created.\nResolvers:\nA resolver is a piece of logic attached to a specific field in the GraphQL Schema (e.g., mutation createEvent). Its job is to receive the GraphQL request, forward it to the corresponding Data Source, and then process the returned result.\nIn this lab, we will create the necessary Data Sources and then attach resolvers to complete the API processing flow.\nSteps 1. Create a Data Source for DynamoDB Go to the AppSync Console.\nSelect the API you are working on.\nNavigate to the Data Sources tab.\nClick Add Data Source.\nName the data source: DynamoDB_Table_Source\nSelect Amazon DynamoDB table as the Data Source type.\nRegion: ap-southeast-1\nTable name: RealtimeQAPlatform-Table\nClick Create.\nNote: This is the data source that connects directly to DynamoDB. We will use it in the resolvers later.\n2. Create Data Sources for Lambda Functions Repeat the following steps for each Lambda function you created in 4.2 Deploy Logic Functions with AWS Lambda:\nClick Add Data Source.\nName the data source according to the corresponding Lambda function (e.g., Lambda_createEvent_Source).\nSelect AWS Lambda Function.\nRegion: ap-southeast-1\nFunction: Select the corresponding function (e.g., createEventFunction)\nClick Create.\nNote: This is the data source that connects to the Lambda Function. We will use it in the resolvers later.\nList of Lambda functions to create Data Sources for:\ncreateEventFunction listEventsFunction createQuestionFunction upvoteQuestionFunction createPollFunction submitPollVoteFunction 3. Attach Resolvers 3.1. Attach resolver for Query getEvent(...) In the left menu, select Schema.\nOn the right side of the page, you will see the Resolvers section. Find the Query getEvent(...): Event.\nClick Attach.\nSelect Data Source: DynamoDB_Table_Source\nResolver Runtime: AppSync Javascript as shown below.\nClick Create.\nIn the code window, paste the following code:\nimport { util } from \u0026#39;@aws-appsync/utils\u0026#39;; export function request(ctx) { const { id: eventId } = ctx.args; return { operation: \u0026#39;Query\u0026#39;, query: { expression: \u0026#39;PK = :pk\u0026#39;, expressionValues: { \u0026#39;:pk\u0026#39;: util.dynamodb.toDynamoDB(`EVENT#${eventId}`), }, }, }; } export function response(ctx) { if (ctx.error) { return util.error(ctx.error.message, ctx.error.type); } const items = ctx.result.items; if (!items || items.length === 0) { return util.error(`Event with id \u0026#39;${ctx.args.id}\u0026#39; not found.`, \u0026#34;NotFound\u0026#34;); } let event = {}; const questions = []; const polls = []; for (const item of items) { if (item.SK.startsWith(\u0026#39;METADATA\u0026#39;)) { event = item; } else if (item.SK.startsWith(\u0026#39;QUESTION#\u0026#39;)) { questions.push(item); } else if (item.SK.startsWith(\u0026#39;POLL#\u0026#39;)) { polls.push(item); } } event.questions = questions; event.polls = polls; return event; } Click Save to save the resolver. Note: getEvent() is the only resolver using AppSync Javascript. The other resolvers use Velocity Template Language (VTL).\n3.2. Attach resolver for Mutation CreateEvent(...) In the left menu, select Schema.\nOn the right side of the page, you will see the Resolvers section. Find the CreateEvent(...) function under Mutation.\nClick Attach.\nSelect Data Source: Lambda_createEvent_Source\nResolver Runtime: Velocity Template Language (VTL) as shown below.\nClick Create.\nAfter creation, a code window will appear as shown below.\nContinue similarly for other Mutations/Queries with their corresponding Lambda functions:\nMutation/Query Name Data Source Resolver Runtime CreateQuestion(...) Lambda_createQuestion_Source Velocity Template Language (VTL) UpvoteQuestion(...) Lambda_upvoteQuestion_Source Velocity Template Language (VTL) SubmitPollVote(...) Lambda_submitPollVote_Source Velocity Template Language (VTL) CreatePoll(...) Lambda_createPoll_Source Velocity Template Language (VTL) listEvents Lambda_listEvents_Source Velocity Template Language (VTL) Notes:\nMake sure to select the correct Data Source for each Lambda Function. All these resolvers use Velocity Template Language (VTL). Follow the same steps as the instructions for CreateEvent(...). "
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/4-s3log/",
	"title": "Building a Real-time API with AWS AppSync and Lambda",
	"tags": [],
	"description": "",
	"content": "After setting up the database, authentication, and permissions, it\u0026rsquo;s time to build the API layer. This layer acts as a bridge, allowing the frontend application to communicate and interact with the backend securely and efficiently. We will use AWS AppSync to create a powerful GraphQL API, combined with AWS Lambda to handle complex business logic.\nIntroduction to AWS AppSync and GraphQL AWS AppSync is a fully managed service that simplifies application development by allowing you to create a flexible GraphQL API.\nWhat is GraphQL?\nGraphQL is a query language for APIs that allows clients to request exactly the data they need—nothing more, nothing less. This helps reduce the amount of data transferred over the network and speeds up the application. Why use AppSync?\nAppSync handles all the complex tasks such as parsing requests, connecting to data sources like DynamoDB and Lambda, and especially managing real-time connections through GraphQL Subscriptions. In this lab, we will create an AppSync API, define the data structure through a GraphQL Schema, and configure authentication methods.\n"
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/5-portfwd/",
	"title": "Port Forwarding",
	"tags": [],
	"description": "",
	"content": "\rPort Forwarding is a useful way to redirect network traffic from one IP address - Port to another IP address - Port. With Port Forwarding we can access an EC2 instance located in the private subnet from our workstation.\nWe will configure Port Forwarding for the RDP connection between our machine and Private Windows Instance located in the private subnet we created for this exercise.\nCreate IAM user with permission to connect SSM Go to IAM service management console Click Users , then click Add users. At the Add user page. In the User name field, enter Portfwd. Click on Access key - Programmatic access. Click Next: Permissions. Click Attach existing policies directly.\nIn the search box, enter ssm. Click on AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user. Save Access key ID and Secret access key information to perform AWS CLI configuration.\nInstall and Configure AWS CLI and Session Manager Plugin To perform this hands-on, make sure your workstation has AWS CLI and Session Manager Plugin installed -manager-working-with-install-plugin.html)\nMore hands-on tutorials on installing and configuring the AWS CLI can be found here.\nWith Windows, when extracting the Session Manager Plugin installation folder, run the install.bat file with Administrator permission to perform the installation.\nImplement Portforwarding Run the command below in Command Prompt on your machine to configure Port Forwarding. aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region (your region) Windows Private Instance Instance ID information can be found when you view the EC2 Windows Private Instance server details.\nExample command: C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026#34;3389\u0026#34;,localPortNumber=\u0026#34;9999\u0026#34; --region ap-southeast-1 If your command gives an error like below: SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nProve that you have not successfully installed the Session Manager Plugin. You may need to relaunch Command Prompt after installing Session Manager Plugin.\nConnect to the Private Windows Instance you created using the Remote Desktop tool on your workstation. In the Computer section: enter localhost:9999. Return to the administration interface of the System Manager - Session Manager service. Click tab Session history. We will see session logs with Document name AWS-StartPortForwardingSession. Congratulations on completing the lab on how to use Session Manager to connect and store session logs in S3 bucket. Remember to perform resource cleanup to avoid unintended costs.\n"
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/6-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance Go to EC2 service management console\nClick Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm. Go to IAM service management console\nClick Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role. Click Users. Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user. Delete S3 bucket Access System Manager - Session Manager service management console.\nClick the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save. Go to S3 service management console\nClick on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit. After deleting all objects in the bucket, click Delete\nEnter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket. Delete VPC Endpoints Go to VPC service management console Click Endpoints. Select the 4 endpoints we created for the lab including SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints. In the confirm box, enter delete.\nClick Delete to proceed with deleting endpoints. Click the refresh icon, check that all endpoints have been deleted before proceeding to the next step.\nDelete VPC Go to VPC service management console\nClick Your VPCs. Click on Lab VPC. Click Actions. Click Delete VPC. In the confirm box, enter delete to confirm, click Delete to delete Lab VPC and related resources.\n"
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/5-portfwd/5.1-setup/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/aws-serverless-qa-app/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]